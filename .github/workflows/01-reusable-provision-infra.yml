name: 'Reusable: Provision Infrastructure'

on:
  workflow_call:
    inputs:
      environment:
        description: 'Environment to deploy'
        required: true
        type: string
    outputs:
      kubeconfig:
        description: "Kubeconfig file content"
        value: ${{ jobs.provision.outputs.kubeconfig }}
      control_plane_ip:
        description: "Control Plane IP"
        value: ${{ jobs.provision.outputs.control_plane_ip }}
      kafka_ip:
        description: "Kafka Node IP"
        value: ${{ jobs.provision.outputs.kafka_ip }}

env:
  TF_VERSION: '1.13.4'

jobs:
  provision:
    name: Provision ${{ inputs.environment }} infrastructure
    runs-on: ubuntu-latest
    outputs:
      kubeconfig: ${{ steps.export_kubeconfig.outputs.kubeconfig }}
      control_plane_ip: ${{ steps.tf_output.outputs.control_ip }}
      kafka_ip: ${{ steps.tf_output.outputs.kafka_ip }}

    steps:
      - name: Checkout Infra Repository
        uses: actions/checkout@v4
        with:
          path: infra

      - name: Setup Terraform ${{ env.TF_VERSION }}
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: ${{ env.TF_VERSION }}
          terraform_wrapper: false

      - name: Install hcloud CLI
        run: |
          curl -fsSL https://github.com/hetznercloud/cli/releases/download/v1.47.0/hcloud-linux-amd64.tar.gz | tar -xz
          chmod +x hcloud
          sudo mv hcloud /usr/local/bin/
          hcloud version

      - name: Setup SSH keys
        run: |
          mkdir -p ~/.ssh
          echo "${{ secrets.SSH_PRIVATE_KEY }}" > ~/.ssh/id_ed25519
          echo "${{ secrets.SSH_PUBLIC_KEY }}" > ~/.ssh/id_ed25519.pub
          chmod 600 ~/.ssh/id_ed25519
          chmod 644 ~/.ssh/id_ed25519.pub

      - name: Create or Get Primary IPs
        id: primary_ips
        run: |
          export HCLOUD_TOKEN="${{ secrets.HCLOUD_TOKEN }}"
          ENV="${{ inputs.environment }}"
          CLUSTER="k3s-trading"
          CONTROL_IP_NAME="${ENV}-${CLUSTER}-control-ip"
          CONTROL_IP_ID=$(hcloud primary-ip list -o noheader -o columns=id,name | grep "$CONTROL_IP_NAME" | awk '{print $1}')
          if [ -z "$CONTROL_IP_ID" ]; then
            CONTROL_IP_ID=$(hcloud primary-ip create --type ipv4 --name "$CONTROL_IP_NAME" --datacenter nbg1-dc3 --label environment=$ENV --label cluster=$CLUSTER --label role=control-plane -o json | jq -r '.primary_ip.id')
          fi
          echo "control_plane_primary_ip_id=$CONTROL_IP_ID" >> $GITHUB_OUTPUT
          
          KAFKA_IP_NAME="${ENV}-${CLUSTER}-kafka-ip"
          KAFKA_IP_ID=$(hcloud primary-ip list -o noheader -o columns=id,name | grep "$KAFKA_IP_NAME" | awk '{print $1}')
          if [ -z "$KAFKA_IP_ID" ]; then
            KAFKA_IP_ID=$(hcloud primary-ip create --type ipv4 --name "$KAFKA_IP_NAME" --datacenter nbg1-dc3 --label environment=$ENV --label cluster=$CLUSTER --label role=kafka -o json | jq -r '.primary_ip.id')
          fi
          echo "kafka_primary_ip_id=$KAFKA_IP_ID" >> $GITHUB_OUTPUT

      - name: Terraform Init
        working-directory: infra
        run: terraform init

      - name: Terraform Apply
        working-directory: infra
        run: terraform apply -auto-approve -var-file="environments/${{ inputs.environment }}.tfvars"
        env:
          TF_VAR_hcloud_token: ${{ secrets.HCLOUD_TOKEN }}
          TF_VAR_ssh_public_key: ${{ secrets.SSH_PUBLIC_KEY }}
          TF_VAR_control_plane_primary_ip_id: ${{ steps.primary_ips.outputs.control_plane_primary_ip_id }}
          TF_VAR_kafka_primary_ip_id: ${{ steps.primary_ips.outputs.kafka_primary_ip_id }}

      - name: Extract Terraform Outputs
        id: tf_output
        working-directory: infra
        run: |
          CONTROL_IP=$(terraform output -raw k3s_control_public_ip)
          KAFKA_IP=$(terraform output -json kafka_server_public_ips | jq -r '.[0]')
          echo "control_ip=$CONTROL_IP" >> $GITHUB_OUTPUT
          echo "kafka_ip=$KAFKA_IP" >> $GITHUB_OUTPUT

      - name: Verify SSH and Cloud-init
        run: |
          set -e
          CONTROL_IP=${{ steps.tf_output.outputs.control_ip }}
          KAFKA_IP=${{ steps.tf_output.outputs.kafka_ip }}
          
          echo "==> Waiting for SSH on control plane ($CONTROL_IP)..."
          SSH_READY=false
          for i in {1..30}; do 
            if ssh -o StrictHostKeyChecking=no -o ConnectTimeout=5 root@$CONTROL_IP "echo 'SSH ready'" 2>/dev/null; then
              SSH_READY=true
              break
            fi
            sleep 10
          done
          if [ "$SSH_READY" = false ]; then
            echo "ERROR: SSH connection to control plane failed after 5 minutes"
            exit 1
          fi
          
          echo "==> Waiting for SSH on kafka node ($KAFKA_IP)..."
          SSH_READY=false
          for i in {1..30}; do 
            if ssh -o StrictHostKeyChecking=no -o ConnectTimeout=5 root@$KAFKA_IP "echo 'SSH ready'" 2>/dev/null; then
              SSH_READY=true
              break
            fi
            sleep 10
          done
          if [ "$SSH_READY" = false ]; then
            echo "ERROR: SSH connection to kafka node failed after 5 minutes"
            exit 1
          fi
          
          echo "==> Waiting for K3s control plane to be ready (checking /root/k3s-ready.txt)..."
          K3S_READY=false
          for i in {1..60}; do 
            if ssh -o StrictHostKeyChecking=no root@$CONTROL_IP "test -f /root/k3s-ready.txt" 2>/dev/null; then
              echo "✓ K3s control plane is ready!"
              K3S_READY=true
              break
            fi
            echo "Attempt $i/60: K3s not ready yet, waiting 5s..."
            sleep 5
          done
          
          if [ "$K3S_READY" = false ]; then
            echo ""
            echo "ERROR: K3s control plane did not become ready within 5 minutes"
            echo "==> Gathering diagnostic information..."
            echo ""
            echo "--- Cloud-init status ---"
            ssh -o StrictHostKeyChecking=no root@$CONTROL_IP "cloud-init status --long" || echo "Failed to get cloud-init status"
            echo ""
            echo "--- Marker files in /root ---"
            ssh -o StrictHostKeyChecking=no root@$CONTROL_IP "ls -la /root/*.txt 2>/dev/null" || echo "No marker files found"
            echo ""
            echo "--- Last 100 lines of cloud-init output log ---"
            ssh -o StrictHostKeyChecking=no root@$CONTROL_IP "tail -100 /var/log/cloud-init-output.log" || echo "Failed to get cloud-init logs"
            echo ""
            echo "--- K3s service status ---"
            ssh -o StrictHostKeyChecking=no root@$CONTROL_IP "systemctl status k3s --no-pager" || echo "K3s service not found"
            echo ""
            exit 1
          fi
          
          echo "==> Transferring K3s token to kafka node..."
          K3S_TOKEN=$(ssh -o StrictHostKeyChecking=no root@$CONTROL_IP "cat /var/lib/rancher/k3s/server/node-token" 2>/dev/null)
          if [ -z "$K3S_TOKEN" ]; then
            echo "ERROR: Failed to retrieve K3s token from control plane"
            exit 1
          fi
          ssh -o StrictHostKeyChecking=no root@$KAFKA_IP "echo '$K3S_TOKEN' > /tmp/k3s-token && chmod 600 /tmp/k3s-token"
          echo "✓ Token transferred"
          
          echo "==> Waiting for K3s agent on kafka node to be ready (checking /root/k3s-agent-ready.txt)..."
          AGENT_READY=false
          for i in {1..60}; do 
            if ssh -o StrictHostKeyChecking=no root@$KAFKA_IP "test -f /root/k3s-agent-ready.txt" 2>/dev/null; then
              echo "✓ K3s agent is ready!"
              AGENT_READY=true
              break
            fi
            echo "Attempt $i/60: K3s agent not ready yet, waiting 5s..."
            sleep 5
          done
          
          if [ "$AGENT_READY" = false ]; then
            echo ""
            echo "ERROR: K3s agent did not become ready within 5 minutes"
            echo "==> Gathering diagnostic information..."
            echo ""
            echo "--- Cloud-init status (kafka node) ---"
            ssh -o StrictHostKeyChecking=no root@$KAFKA_IP "cloud-init status --long" || echo "Failed to get cloud-init status"
            echo ""
            echo "--- Marker files in /root (kafka node) ---"
            ssh -o StrictHostKeyChecking=no root@$KAFKA_IP "ls -la /root/*.txt 2>/dev/null" || echo "No marker files found"
            echo ""
            echo "--- Last 100 lines of cloud-init output log (kafka node) ---"
            ssh -o StrictHostKeyChecking=no root@$KAFKA_IP "tail -100 /var/log/cloud-init-output.log" || echo "Failed to get cloud-init logs"
            echo ""
            echo "--- K3s agent service status ---"
            ssh -o StrictHostKeyChecking=no root@$KAFKA_IP "systemctl status k3s-agent --no-pager" || echo "K3s agent service not found"
            echo ""
            exit 1
          fi
          
          echo "==> Cloud-init verification complete!"

      - name: Get Kubeconfig
        id: get_kubeconfig
        run: |
          CONTROL_IP=${{ steps.tf_output.outputs.control_ip }}
          mkdir -p $HOME/.kube
          ssh -o StrictHostKeyChecking=no root@$CONTROL_IP "cat /etc/rancher/k3s/k3s.yaml" > $HOME/.kube/config
          sed -i "s/127.0.0.1/$CONTROL_IP/g" $HOME/.kube/config
          echo "kubeconfig_path=$HOME/.kube/config" >> $GITHUB_OUTPUT

      - name: Export Kubeconfig content
        id: export_kubeconfig
        run: |
          KUBECONFIG_CONTENT=$(cat ${{ steps.get_kubeconfig.outputs.kubeconfig_path }})
          # This is a trick to set a multiline output
          echo "kubeconfig<<EOF" >> $GITHUB_OUTPUT
          echo "$KUBECONFIG_CONTENT" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT
