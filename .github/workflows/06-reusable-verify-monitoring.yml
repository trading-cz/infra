name: '06 Reusable: Verify Monitoring Operators'

on:
  workflow_call:
    inputs:
      control_plane_ip:
        description: 'Control Plane IP'
        required: true
        type: string
    secrets:
      ssh_private_key:
        description: 'SSH private key for server access'
        required: true

jobs:
  verify-monitoring:
    name: Verify Monitoring Stack
    runs-on: ubuntu-latest
    steps:
      - name: Setup SSH Key
        run: |
          mkdir -p ~/.ssh
          echo "${{ secrets.ssh_private_key }}" > ~/.ssh/id_ed25519
          chmod 600 ~/.ssh/id_ed25519

      - name: Install kubectl
        run: |
          curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
          chmod +x kubectl
          sudo mv kubectl /usr/local/bin/

      - name: Download Kubeconfig
        run: |
          CONTROL_IP="${{ inputs.control_plane_ip }}"
          mkdir -p ~/.kube
          
          echo "üì• Downloading kubeconfig from $CONTROL_IP..."
          for i in {1..5}; do
            if ssh -o StrictHostKeyChecking=no -o ConnectTimeout=10 root@$CONTROL_IP "cat /etc/rancher/k3s/k3s.yaml" > ~/.kube/config 2>/dev/null; then
              sed -i "s/127.0.0.1/$CONTROL_IP/g" ~/.kube/config
              chmod 600 ~/.kube/config
              echo "‚úÖ Kubeconfig downloaded"
              break
            fi
            echo "‚ö†Ô∏è Retry $i/5..."
            sleep 5
          done

      - name: Verify Prometheus Operator
        id: prometheus
        continue-on-error: true
        run: |
          echo "üîç Checking Prometheus Operator in monitoring namespace..."
          
          # Check if monitoring namespace exists
          if kubectl get namespace monitoring &>/dev/null; then
            echo "‚úÖ Monitoring namespace exists"
          else
            echo "‚ùå Monitoring namespace not found"
            exit 1
          fi
          
          # Debug: Show all pods in monitoring namespace
          echo "üìä All Monitoring Namespace Pods:"
          kubectl get pods -n monitoring -o wide
          
          # Debug: Show all pod labels
          echo "üìã Pod Labels in monitoring namespace:"
          kubectl get pods -n monitoring --show-labels
          
          # Wait for prometheus operator pods (kube-prometheus-stack pattern)
          echo "‚è≥ Waiting for Prometheus Operator controller pod..."
          # kube-prometheus-stack deploys as "prometheus-operator-kube-p-operator-*" with label app=kube-prometheus-stack-operator
          if kubectl wait --for=condition=Ready pod -l app=kube-prometheus-stack-operator -n monitoring --timeout=60s 2>/dev/null; then
            echo "‚úÖ Prometheus Operator controller is Ready"
          else
            echo "‚ö†Ô∏è Prometheus Operator controller not ready yet"
            kubectl get pods -n monitoring -l app=kube-prometheus-stack-operator -o wide
          fi
          
          # Check all critical monitoring components
          echo "üîß Checking Prometheus Stack Components:"
          REQUIRED_COMPONENTS=("kube-prometheus-stack-prometheus-operator" "kube-state-metrics" "prometheus-node-exporter" "prometheus")
          for component in "${REQUIRED_COMPONENTS[@]}"; do
            COUNT=$(kubectl get pods -n monitoring -l "app.kubernetes.io/name=$component" --no-headers 2>/dev/null | grep -c "Running" || echo "0")
            if [ "$COUNT" -gt 0 ] 2>/dev/null; then
              echo "‚úÖ $component: $COUNT pod(s) Running"
            else
              echo "‚ö†Ô∏è $component: checking alternative labels..."
              # Try component-specific labels
              case "$component" in
                "kube-prometheus-stack-prometheus-operator")
                  kubectl get pods -n monitoring -l "app=kube-prometheus-stack-operator" --no-headers 2>/dev/null | head -1 && echo "‚úÖ Found via app=kube-prometheus-stack-operator" || echo "   Not found"
                  ;;
                "prometheus")
                  kubectl get pods -n monitoring -l "app.kubernetes.io/name=prometheus" --no-headers 2>/dev/null | head -1 && echo "‚úÖ Found" || echo "   Not found"
                  ;;
                *)
                  echo "   Not found with label app.kubernetes.io/name=$component"
                  ;;
              esac
            fi
          done

      - name: Verify Grafana Operator
        id: grafana
        continue-on-error: true
        run: |
          echo "üé® Checking Grafana Operator in monitoring namespace..."
          
          # Wait for grafana-operator pod to be ready
          echo "‚è≥ Waiting for Grafana Operator pod..."
          if kubectl wait --for=condition=Ready pods -l app.kubernetes.io/name=grafana-operator -n monitoring --timeout=300s 2>/dev/null; then
            echo "‚úÖ Grafana Operator pod is Ready"
          else
            echo "‚ö†Ô∏è Grafana Operator pod not ready within timeout"
            exit 1
          fi
          
          # Check operator pod details
          echo "üìä Grafana Operator Pod Details:"
          kubectl get pods -n monitoring -l app.kubernetes.io/name=grafana-operator -o wide

      - name: Verify CRDs
        id: crds
        continue-on-error: true
        run: |
          echo "üìã Checking Custom Resource Definitions..."
          
          # kube-prometheus-stack registers CRDs with monitoring.coreos.com group
          # Debug: Show actual CRDs
          echo "üîç All monitoring.coreos.com CRDs:"
          kubectl get crd | grep -E "monitoring\.coreos\.com|grafana\.integreatly\.org" || echo "No CRDs found"
          
          # Check for Prometheus CRDs (with monitoring.coreos.com group)
          PROMETHEUS_CRDS=(
            "prometheuses.monitoring.coreos.com"
            "prometheusrules.monitoring.coreos.com"
            "servicemonitors.monitoring.coreos.com"
            "podmonitors.monitoring.coreos.com"
          )
          
          echo "üîß Prometheus Stack CRDs:"
          PROM_READY=true
          for crd in "${PROMETHEUS_CRDS[@]}"; do
            if kubectl get crd "$crd" &>/dev/null; then
              echo "‚úÖ CRD $crd exists"
            else
              echo "‚ùå CRD $crd not found"
              PROM_READY=false
            fi
          done
          
          # Check for Grafana CRDs
          GRAFANA_CRDS=(
            "grafanas.grafana.integreatly.org"
            "grafanadatasources.grafana.integreatly.org"
            "grafanadashboards.grafana.integreatly.org"
          )
          
          echo "üîß Grafana CRDs:"
          GRAFANA_READY=true
          for crd in "${GRAFANA_CRDS[@]}"; do
            if kubectl get crd "$crd" &>/dev/null; then
              echo "‚úÖ CRD $crd exists"
            else
              echo "‚ùå CRD $crd not found"
              GRAFANA_READY=false
            fi
          done
          
          # If Prometheus CRDs missing, capture more debug info
          if [ "$PROM_READY" = false ]; then
            echo "üîç Prometheus Operator pod status:"
            kubectl get pods -n monitoring -l app.kubernetes.io/name=prometheus-operator -o wide
            echo "üîç Prometheus Operator pod events:"
            kubectl describe pod -n monitoring -l app.kubernetes.io/name=prometheus-operator 2>/dev/null || echo "No pods found"
          fi

      - name: Check Operator Logs
        if: always()
        continue-on-error: true
        run: |
          echo "::group::Prometheus Operator Logs"
          kubectl logs -n monitoring -l app=kube-prometheus-stack-operator --tail=50 2>/dev/null || echo "No logs found"
          echo "::endgroup::"
          
          echo "::group::Grafana Operator Logs"
          kubectl logs -n monitoring -l app.kubernetes.io/name=grafana-operator --tail=50 || echo "No logs found"
          echo "::endgroup::"
          
          echo "::group::kube-state-metrics Logs"
          kubectl logs -n monitoring -l app.kubernetes.io/name=kube-state-metrics --tail=50 || echo "No logs found"
          echo "::endgroup::"
          
          echo "::group::All Pod Details"
          kubectl get pods -n monitoring -o yaml
          echo "::endgroup::"

      - name: Summary
        if: always()
        run: |
          echo "========================================"
          echo "  Monitoring Operators Verification"
          echo "========================================"
          
          FAILED=false
          
          if [ "${{ steps.prometheus.outcome }}" == "success" ]; then
            echo "‚úÖ Prometheus Operator:  Ready"
          else
            echo "‚ùå Prometheus Operator:  FAILED"
            FAILED=true
          fi
          
          if [ "${{ steps.grafana.outcome }}" == "success" ]; then
            echo "‚úÖ Grafana Operator:     Ready"
          else
            echo "‚ùå Grafana Operator:     FAILED"
            FAILED=true
          fi
          
          if [ "${{ steps.crds.outcome }}" == "success" ]; then
            echo "‚úÖ CRDs:                 Deployed"
          else
            echo "‚ö†Ô∏è  CRDs:                 Some missing"
            FAILED=true
          fi
          
          echo "========================================"
          echo ""
          echo "üìä **Monitoring Stack Status:**"
          echo "- **Prometheus Operator**: Scrapes K3s, Kafka, & apps"
          echo "- **Grafana Operator**: Manages dashboards as code"
          echo "- **kube-state-metrics**: K8s object metrics"
          echo "- **node-exporter**: Node-level metrics"
          echo ""
          echo "‚è≠Ô∏è  **Next Steps:**"
          echo "1. Deploy Prometheus instance (config/base/monitoring/)"
          echo "2. Deploy Grafana instance (config/base/monitoring/)"
          echo "3. Create ServiceMonitors for scrape targets"
          echo "4. Create GrafanaDashboards for visualization"
          echo "========================================"
          
          if [ "$FAILED" = true ]; then
            exit 1
          fi
