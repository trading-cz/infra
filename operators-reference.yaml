# REFERENCE DOCUMENTATION - Operators Bootstrap
# This file documents the Helm installations performed by cloud-init in modules/k3s-server/cloud-init.yaml
# It is NOT deployed by Terraform - it's for documentation and reference purposes only.
# 
# For actual installation details, refer to:
# - modules/k3s-server/cloud-init.yaml (execution)
# - modules/prometheus-operator/VERSION (Prometheus Operator version)
# - modules/grafana-operator/VERSION (Grafana Operator version)
#
# These operators are installed BEFORE ArgoCD, providing the CRDs needed for:
# - Prometheus instances (config/base/monitoring/prometheus/)
# - Grafana instances (config/base/monitoring/grafana/)
# - Dashboards, ServiceMonitors, etc. (managed via ArgoCD)

---
# PROMETHEUS OPERATOR
# Helm Chart: prometheus-community/kube-prometheus-stack
# Version: 0.77.0 (see modules/prometheus-operator/VERSION)
# Namespace: monitoring
# Installation Method: cloud-init (during K3s control plane bootstrap)
#
# Provides CRDs:
#   - Prometheus
#   - AlertManager
#   - ServiceMonitor (for scrape targets)
#   - PodMonitor
#   - Probe
#   - PrometheusRule
#
# Components installed:
#   - prometheus-operator controller
#   - kube-state-metrics (K8s object metrics)
#   - node-exporter (node-level metrics: CPU, memory, network, disk)
#   - prometheus-operator webhook (validation)

apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-operator-bootstrap
  namespace: kube-system
  labels:
    app.kubernetes.io/name: prometheus-operator
    app.kubernetes.io/component: bootstrap-reference
    app.kubernetes.io/managed-by: terraform
data:
  helm-install-command: |
    helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
    helm repo update
    helm install prometheus-operator prometheus-community/kube-prometheus-stack \
      --namespace monitoring \
      --create-namespace \
      --version 0.77.0 \
      --set prometheus.prometheusSpec.retention=30d \
      --set prometheus.prometheusSpec.storageSpec.volumeClaimTemplate.spec.resources.requests.storage=20Gi \
      --set prometheus.prometheusSpec.serviceMonitorSelectorNilUsesHelmValues=false \
      --set grafana.enabled=false \
      --set alertmanager.enabled=false \
      --wait \
      --timeout 5m
  
  helm-values-explanation: |
    prometheus.prometheusSpec.retention=30d
      → Metrics retained for 30 days before purged
    
    prometheus.prometheusSpec.storageSpec.volumeClaimTemplate.spec.resources.requests.storage=20Gi
      → PersistentVolume allocated for metrics storage (20GB)
      → Should hold ~30 days of metrics for 50+ strategies
    
    prometheus.prometheusSpec.serviceMonitorSelectorNilUsesHelmValues=false
      → Prometheus scrapes ALL ServiceMonitors (not filtered by labels)
      → Allows ArgoCD to add scrape targets via config/ repo
    
    grafana.enabled=false
      → Grafana NOT installed by Prometheus chart
      → Grafana Operator installs it separately
    
    alertmanager.enabled=false
      → AlertManager NOT installed (can be added later)
      → Reduce initial complexity
    
    --wait --timeout 5m
      → Wait up to 5 minutes for operator pod to be Ready
      → Verification: kubectl wait --for=condition=Ready pods -l app.kubernetes.io/name=prometheus-operator -n monitoring --timeout=300s

---
# GRAFANA OPERATOR
# Helm Chart: grafana/grafana-operator
# Version: 5.21.3 (see modules/grafana-operator/VERSION)
# Namespace: monitoring
# Installation Method: cloud-init (during K3s control plane bootstrap)
#
# Provides CRDs:
#   - Grafana (instances)
#   - GrafanaDatasource (connections to Prometheus, etc.)
#   - GrafanaDashboard (dashboards as code)
#   - GrafanaFolder (dashboard organization)
#   - GrafanaContact (alert contacts - future)
#
# Components installed:
#   - grafana-operator controller
#   - Webhook (validation)

apiVersion: v1
kind: ConfigMap
metadata:
  name: grafana-operator-bootstrap
  namespace: kube-system
  labels:
    app.kubernetes.io/name: grafana-operator
    app.kubernetes.io/component: bootstrap-reference
    app.kubernetes.io/managed-by: terraform
data:
  helm-install-command: |
    helm repo add grafana https://grafana.github.io/helm-charts
    helm repo update
    helm install grafana-operator grafana/grafana-operator \
      --namespace monitoring \
      --version 5.21.3 \
      --wait \
      --timeout 5m
  
  helm-values-explanation: |
    Default values used (no customization needed for operator installation)
    
    Grafana instance (CR) configuration happens in config/ repo:
      - config/base/monitoring/grafana/grafana-cr.yaml (instance)
      - config/base/monitoring/grafana/grafana-datasource.yaml (Prometheus connection)
      - config/overlays/dev/monitoring/ (dev-specific overrides)
      - config/overlays/prod/monitoring/ (prod-specific overrides)
    
    Verification: kubectl wait --for=condition=Ready pods -l app.kubernetes.io/name=grafana-operator -n monitoring --timeout=300s

---
# BOOTSTRAP SEQUENCE
# 1. Cloud-init Helm adds repositories (prometheus-community, grafana)
# 2. Prometheus Operator installed → CRDs registered → kube-state-metrics, node-exporter running
# 3. Grafana Operator installed → CRDs registered
# 4. Both verified via kubectl wait --for=condition=Ready
# 5. K3s control plane ready
# 6. GitHub Actions verifies operators (06-reusable-verify-monitoring.yml)
# 7. ArgoCD deployed
# 8. ArgoCD syncs config/base/monitoring/ → deploys Prometheus/Grafana instances & dashboards

---
# UPGRADE PATH
# To upgrade operators in future:
# 1. Update VERSION files:
#    - modules/prometheus-operator/VERSION (e.g., 0.77.0 → 0.78.0)
#    - modules/grafana-operator/VERSION (e.g., 5.21.3 → 5.22.0)
# 2. Update Helm install command in modules/k3s-server/cloud-init.yaml
# 3. Update this reference file (helm-install-command)
# 4. Destroy and redeploy cluster via GitHub Actions
#    (operators always reinstalled from scratch on ephemeral clusters)

---
# TROUBLESHOOTING
# If operators don't install:
# 1. SSH into control-plane: ssh root@<CONTROL_IP>
# 2. Check cloud-init logs: tail -f /var/log/cloud-init-output.log
# 3. Manual verification:
#    kubectl get pods -n monitoring
#    kubectl get crd | grep prometheus
#    kubectl get crd | grep grafana
# 4. Check operator logs:
#    kubectl logs -n monitoring -l app.kubernetes.io/name=prometheus-operator
#    kubectl logs -n monitoring -l app.kubernetes.io/name=grafana-operator
